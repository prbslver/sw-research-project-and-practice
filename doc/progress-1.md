이번 주에 계획했던 것
----------------
* 구글의 검색엔진(pageRank, inverted indexing 등) 에 대해 조사한다. 
* 위를 개선하기 위한 방법으로 제시한, random sampling 기법을 이용한 검색엔진에 대해 생각을 구체화한다.
* morphological analyzer 에 고유명사 등 사전을 추가하는 기법을 알아본다.


이번 주에 한 것
------------
* random sampling 기법을 이용한 검색엔진에 관련해,
  * 자세히 설명을 다시 하자면,
    * 구글 검색엔진의 검색결과는 우수하지만, 경험적으로 원하는 결과가 나오지 않는 경우도 많이 경험했다.
    * 따라서, search query 에 대한 검색결과를 scoring 을 해서 보여주지 않고, 그 search query 를 포함하는 문서에 대해 random sampling 하여 보여주는 단순한 방식을 사용한다.
    * 더 자세하게는,
      * x 축을 search query 에 대해 검색해 나온 문서들의 유용성 (왼쪽으로 갈수록 유용성이 낮음, 오른쪽으로 갈수록 유용성이 높음) 이라 하고,
      * y 축을 문서들의 갯수로 하면,
      * 경험적으로는, 왼쪽일수록 문서들의 갯수가 많고, 오른쪽일수록 문서들의 갯수가 적어지는 분포가 된다.
      * 여기서 random sampling 방식으로 문서를 뽑으면,
      * 유용성이 낮은 문서가 많이 뽑히기야 하겠지만, 구글 scoring 알고리즘이 놓친, 유용성이 높은 문서도 뽑힐 것이라 생각할 수 있다.
  * 위의 random sampling 기법의 정확한 명칭이, 'monte carlo' random sampling 기법이라 한다. 
    * 그러나, 모든 유용성에 대해 같은 확률로 문서를 추출하기 때문에, 유용성이 낮은 문서가 많이 뽑힐 것이다.
  * 따라서, mcmc random sampling 기법을 사용하기로 판단했다.
    * mcmc random sampling 은, random sampling 이기는 하지만, 모분포를 파악하는 데 있어 효율적이라는 장점이 있다.
    * 자세한 사항은 링크로 갈음한다. (https://angeloyeo.github.io/2020/09/17/MCMC.html)
    * 이 원리를 이용하면, 유용성이 높은 문서를 더 간단하게 뽑게 되지 않을까?
      * random 하게 유용성을 선택해서 문서를 뽑고, 이를 반복하겠지만, 
      * mcmc random sampling 특유의 방식에 의해, 모든 유용성에 따른 모든 document 를 뽑게 되지 않을까?
      * 그러면, 유용성 높은 document 를 검색하게 되는 것은 아닐까? 그것도 monte carlo 방식에 비해 빠르게?
* 사전을 추가하는 기법에 앞서, 우선은 apache lucene 의 동작 원리에 대해서 조사했다.
  * 자세히는, apache lucene 내 morphological analyzer 에 사전을 추가하는 것이기 때문에, apache lucene 에 대해서도 알아보아야 한다.


이번 주에 못한 것 (앞으로 할 것)
-------------------------
* 구글 검색엔진에 대해 아직 조사하지 못했다.
  * 사실은, 조사 관련해서 어떤 자료를 읽을지 말지를 결정하기까지는 했다. 
  * 앞으로, 'search engine information retrieval in practice', 'modern information retrieval', 'information retrieval' 이라는 교과서를 읽을 생각이다.
    * 시간이 많이 경과되어, 구글 검색엔진의 작동방식이 이미 교과서에 실릴 정도가 되었다고 판단했다.
    * 아마 구글의 개략적인 작동방식에 대해 알게 될 것이라 생각한다. 자세한 방식은 기업기밀이기 때문이다.
* apache lucene 의 동작과정에 대해 다 알아보지 못했다.
  * 지금까지 조사하면서 읽은 apache lucene documentation, 몇몇 인터넷 문서, 시중에 나온 책 등이 상당히 불친절하게 쓰여져 있어 내용파악에 어려움을 겪고 있다.
  * 다른 자료를 찾아볼 생각이다.


의미있는 것, 아쉬운 것, 느낀 것
------------------------
* random sampling 기법을 사용한 검색엔진에 대한 선행논문이 없다.
  * 내가 뛰어난 연구자이기 때문에 새 연구분야를 개척한 것이 당연히 아니고... 이 연구가 학술적으로는 아마 가치가 없어서 그런 것이 아닌가 싶다.
    * 얘기한대로, 아마 유용성이 낮은 자료를 뽑는 경우가 상당할 것이다. 이는 학술지에 출판할만한 elegance 한 해결책이 아니다.
    * 그러나, 이는 구글의 난점을 해결하는 하나의 대안으로 평가할 만하다고는 생각한다.


전체 대비 진행률 (예상)
------------------
* 구글의 검색엔진(pageRank, inverted indexing 등) 에 대해 조사: 50%
  * 교과서를 읽기만 하면 된다. 얼마 걸릴지는 모르겠지만 시작이 반이라는 느낌으로 50프로 준다.
* 위를 개선하기 위한 방법으로 제시한, random sampling 기법을 이용한 검색엔진에 대해 생각을 구체화: 90% (?)
  * 통계학 이론에 관해서라면 더 보탤 것이 보이지 않는다. 하지만 보탤 것이 더 있을 수 있는 가능성을 배제할 수 없어서 90프로 준다.
* morphological analyzer 에 고유명사 등 사전을 추가하는 기법을 알아본다: 30%
  * apache lucene 동작과정에 대한 다른 읽을 거리 찾는 것까지야 경험상 어렵지는 않겠지만, 구현상 난점을 예상할 수 없어 30프로 준다.
